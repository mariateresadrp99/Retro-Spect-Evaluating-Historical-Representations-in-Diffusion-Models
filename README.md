## Code for "Synthetic History: Evaluating Visual Representations of the Past in Diffusion Models"

![Evaluation Methodology](./evalutation_methodology.png)
As Text-to-Image (TTI) diffusion models become increasingly influential in content creation, growing attention is being directed toward their societal and cultural implications. While prior research has primarily examined demographic and cultural biases, the ability of these models to accurately represent historical contexts remains largely underexplored. In this work, we present a systematic and reproducible methodology for evaluating how TTI systems depict different historical periods. For this purpose, we introduce the HistVis dataset, a curated collection of 30,000 synthetic images generated by three state-of-the-art diffusion models using carefully designed prompts depicting universal human activities across different historical periods. We evaluate generated imagery across three key aspects: (1) Implicit Stylistic Associations: examining default visual styles associated with specific eras; (2) Historical Consistency: identifying anachronisms such as modern artifacts in pre-modern contexts; and (3) Demographic Representation: comparing generated racial and gender distributions against historically plausible baselines. Our findings reveal systematic inaccuracies in historically themed generated imagery, as TTI models frequently stereotype past eras by incorporating unstated stylistic cues, introduce anachronisms, and fail to reflect plausible demographic patterns. By offering a scalable methodology and benchmark for assessing historical representation in generated imagery, this work provides an initial step toward building more historically accurate and culturally aligned TTI models.


## A. The HistVis Dataset

### A1. Dataset Overview
The HistVis dataset consists of 30,000 synthetic images generated from prompts describing 100 universal human activities across 10 historical time periods using three state-of-the-art diffusion models (Stable Diffusion XL, Stable Diffusion 3, FLUX.1-schnell). Each prompt follows the format "A person [activity] in the [historical period]", combining 100 activities (drawn from 20 domains such as art, work, celebration, and communication) with five centuries (17thâ€“21st) and five 20th-century decades (1910s, 1930s, 1950s, 1970s, 1990s). For each activityâ€“period pair, 10 images were generated per model.

The dataset includes comprehensive metadata in a structured CSV format, with each image entry containing:
- image_path: The full image path for direct access
- model: The generative model identifier (Flux_Schnell, SD_3, or SD_XL)
- historical_period: The historical period specified in the prompt
- universal_human_activity: The universal human activity described
- category: The broader category the activity belongs to


### A2. Dataset Access
The dataset is publicly available on [Hugging Face](https://huggingface.co/datasets/latentcanon/HistVis) and can be downloaded using:

```python
# Basic download of CSV metadata
from datasets import load_dataset
import pandas as pd

# Load only the metadata
dataset = load_dataset('csv', data_files='https://huggingface.co/datasets/latentcanon/HistVis/resolve/main/dataset.csv')

# Convert to pandas DataFrame for easier manipulation
df = pd.DataFrame(dataset['train'])
print(f"Dataset contains {len(df)} entries")

# View first few entries
print(df.head())

```
## Licence
The HistVis dataset is released under the Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0) license.

## B. Evaluation Methods

### B1. Visual Style Prediction

This module predicts visual styles in images generated by TTI models. We use a VGG16-based classifier fine-tuned on six style categories: drawings, engravings, illustrations, paintings, photography (color or b&w). The script also computes a colorfulness score to help distinguish between monochrome and color photography.

## Files

- `predict_visual_style.py`: Main script for running style prediction
- `utils.py`: Helper functions

## Model Weights

The pretrained model is available on [Hugging Face](https://huggingface.co/mariateresadrp/visual_style_predictor) and can be downloaded using `huggingface_hub`:

```python
from huggingface_hub import hf_hub_download
from tensorflow.keras.models import load_model

model_path = hf_hub_download(
    repo_id="mariateresadrp/visual_style_predictor",
    filename="best_vgg16_only_last.keras"
)

model = load_model(model_path)
```

ðŸ“Š Visual Style Dominance (VSD) Score
To quantify how strongly a model defaults to a specific style for a given historical period, we define the Visual Style Dominance (VSD) Score:

VSD(m, t) = max<sub>s</sub> P<sub>m</sub>(s | t)

Where:

m is the model,

t is the time period (e.g., 1910s, 20th century),

s is one of the six predicted styles,

P<sub>m</sub>(s | t) is the proportion of images from model m and time period t that were classified into style s.

A VSD score close to 1.0 indicates strong stylistic convergence (homogeneity), while a lower VSD score reflects higher visual diversity. The corresponding dominant style is the one with the highest predicted proportion for that period and model.


### B2. Anachronism Detection 

This module detects and analyzes anachronisms in synthetic images generated by text-to-image (TTI) models. It combines LLM-generated question prompts with vision-language model (VLM) analysis and computes anachronism frequency & severity metrics.
## Files

- `llm_anachronism_proposal.py`: Given a prompt with a historical condition, an LLM (GPT-4o) proposes potential anachronisms in the generated images, as well as identification questions for a VLM model.
- `anachronism_detection.py`: Runs anachronism detection using a VLM (GPT-4 Turbo).
- `compute_anachr_freq_and_sever.py`: Compute anachronism frequency and severity metrics.
- `19th_century.json`: Includes a sample JSON input with prompts and questions for the VLM (GPT-4 Turbo).

## Usage
```bash

# LLM Anachronism Detection
python generate_anachronism_questions.py \
  --input_txt path/to/prompts.txt \

# VLM Anachronism Detection
python detect_anachronisms.py \
  --image_root path/to/images \
  --json_file path/to/prompts.json \
  --output_file results.json

# Compute Frequency and Severity Metrics
python analyze_anachronisms.py \
  --json_path results.json \
  --output_csv anachronism_stats.csv
```

### B3. Demographic Representation

This method evaluates whether TTI models generate historically plausible demographic distributions in their outputs, focusing on race and gender. Rather than assuming modern demographic expectations, we compare generated outputs against contextual historical estimates provided by an LLM (GPT-4o). We then compute over- and underrepresentation scores by comparing model outputs with LLM predictions.

## Files: 
- `generate_demographic_estimates.py`: Uses an LLM (GPT-4o) to infer plausible demographic ratios (gender and race) for each prompt
- `evaluate_demographic_alignment.py`: Compares FairFace-predicted outputs to LLM predictions and computes over-/underrepresentation metrics

## Usage:
```bash
# Generate historical demographic estimates from prompts
python generate_demographic_estimates.py \
  --input_txt path/to/prompts.txt \
  --output_json llm_demographics.json

#  Evaluate demographic alignment
python evaluate_demographic_alignment.py \
  --model_outputs_csv fairface_outputs.csv \
  --llm_json llm_demographics.json \
  --output_csv demographic_metrics.csv



