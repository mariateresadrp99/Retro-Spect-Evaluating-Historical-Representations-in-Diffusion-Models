## Code for "Synthetic History: Evaluating Visual Representations of the Past in Diffusion Models"

![Evaluation Methodology](./evalutation_methodology.png)
As Text-to-Image (TTI) diffusion models become increasingly influential in content creation, growing attention is being directed toward their societal and cultural implications. While prior research has primarily examined demographic and cultural biases, the ability of these models to accurately represent historical contexts remains largely underexplored. In this work, we present a systematic and reproducible methodology for evaluating how TTI systems depict different historical periods. For this purpose, we introduce the HistVis dataset, a curated collection of 30,000 synthetic images generated by three state-of-the-art diffusion models using carefully designed prompts depicting universal human activities across different historical periods. We evaluate generated imagery across three key aspects: (1) Implicit Stylistic Associations: examining default visual styles associated with specific eras; (2) Historical Consistency: identifying anachronisms such as modern artifacts in pre-modern contexts; and (3) Demographic Representation: comparing generated racial and gender distributions against historically plausible baselines. Our findings reveal systematic inaccuracies in historically themed generated imagery, as TTI models frequently stereotype past eras by incorporating unstated stylistic cues, introduce anachronisms, and fail to reflect plausible demographic patterns. By offering a scalable methodology and benchmark for assessing historical representation in generated imagery, this work provides an initial step toward building more historically accurate and culturally aligned TTI models.


## A. The HistVis Dataset

### A1. Dataset Overview
The HistVis dataset consists of 30,000 synthetic images generated from prompts describing 100 universal human activities across 10 historical time periods using three state-of-the-art diffusion models (Stable Diffusion XL, Stable Diffusion 3, FLUX.1-schnell). Each prompt follows the format "A person [activity] in the [historical period]", combining 100 activities (drawn from 20 domains such as art, work, celebration, and communication) with five centuries (17th–21st) and five 20th-century decades (1910s, 1930s, 1950s, 1970s, 1990s). For each activity–period pair, 10 images were generated per model.

The dataset includes comprehensive metadata in a structured CSV format, with each image entry containing:
- image_path: The full image path for direct access
- model: The generative model identifier (Flux_Schnell, SD_3, or SD_XL)
- historical_period: The historical period specified in the prompt
- universal_human_activity: The universal human activity described
- category: The broader category the activity belongs to


### A2. Dataset Access
The dataset is publicly available on [Hugging Face](https://huggingface.co/datasets/latentcanon/HistVis) and can be downloaded using:

```python
# Basic download of CSV metadata
from datasets import load_dataset
import pandas as pd

# Load only the metadata
dataset = load_dataset('csv', data_files='https://huggingface.co/datasets/latentcanon/HistVis/resolve/main/dataset.csv')

# Convert to pandas DataFrame for easier manipulation
df = pd.DataFrame(dataset['train'])
print(f"Dataset contains {len(df)} entries")

# View first few entries
print(df.head())

```
## Licence
The HistVis dataset is released under the Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0) license.

## B. Evaluation Methods

### B1. Implicit Stylistic Associations
This module analyzes the stylistic tendencies of text-to-image (TTI) models by predicting visual styles in generated images and calculating a **Visual Style Dominance (VSD)** score.

The module consists of two main scripts:

- `predict_visual_style.py`: Predicts visual styles using a fine-tuned CNN classifier.
- `vsd_scorer.py`: Calculates Visual Style Dominance (VSD) scores based on predictions.

The classifier identifies six visual style categories:
- **Drawings**
- **Engravings**
- **Illustrations**
- **Paintings**
- **Photography (Color)**
- **Photography (Monochrome)**

Since WikiArt does not distinguish between color and monochrome photography, a **colorfulness score** is computed to separate them.

## Installation

```bash
pip install tensorflow pandas numpy matplotlib seaborn huggingface_hub datasets
```

## Usage

### 1. Predicting Visual Styles

**Using the HistVis Dataset and Fine Tuned Model:**

```bash
python visual_style_prediction/predict_visual_style.py --use_hf_dataset --use_hf_model --output_file style_predictions.csv
```

**Using a Custom Dataset and Model:**

```bash
python visual_style_prediction/predict_visual_style.py --dataset_csv your_dataset.csv --your_finetuned_model --output_file predictions.csv
```

### 2. Calculating VSD Scores

```bash
python visual_style_prediction/vsd_scorer.py --output_file style_predictions.csv --output vsd_results.csv 
```


## Model Weights

Our fine tuned model is available on [Hugging Face](https://huggingface.co/mariateresadrp/visual_style_predictor) and can be downloaded using `huggingface_hub`:

```python
from huggingface_hub import hf_hub_download
from tensorflow.keras.models import load_model

model_path = hf_hub_download(
    repo_id="mariateresadrp/visual_style_predictor",
    filename="best_vgg16_only_last.keras"
)

model = load_model(model_path)
```

### B2. Anachronism Detection 

This module detects and analyzes anachronisms in synthetic images generated by text-to-image (TTI) models. It combines LLM-generated question prompts with vision-language model (VLM) analysis and computes anachronism frequency & severity metrics.
## Files

- `llm_anachronism_proposal.py`: Given a prompt with a historical condition, an LLM (GPT-4o) proposes potential anachronisms in the generated images, as well as identification questions for a VLM model.
- `anachronism_detection.py`: Runs anachronism detection using a VLM (GPT-4 Turbo).
- `compute_anachr_freq_and_sever.py`: Compute anachronism frequency and severity metrics.
- `19th_century.json`: Includes a sample JSON input with prompts and questions for the VLM (GPT-4 Turbo).

## Usage
```bash

# LLM Anachronism Detection
python generate_anachronism_questions.py \
  --input_txt path/to/prompts.txt \

# VLM Anachronism Detection
python detect_anachronisms.py \
  --image_root path/to/images \
  --json_file path/to/prompts.json \
  --output_file results.json

# Compute Frequency and Severity Metrics
python analyze_anachronisms.py \
  --json_path results.json \
  --output_csv anachronism_stats.csv
```

### B3. Demographic Representation

This method evaluates whether TTI models generate historically plausible demographic distributions in their outputs, focusing on race and gender. Rather than assuming modern demographic expectations, we compare generated outputs against contextual historical estimates provided by an LLM (GPT-4o). We then compute over- and underrepresentation scores by comparing model outputs with LLM predictions.

## Files: 
- `generate_demographic_estimates.py`: Uses an LLM (GPT-4o) to infer plausible demographic ratios (gender and race) for each prompt
- `evaluate_demographic_alignment.py`: Compares FairFace-predicted outputs to LLM predictions and computes over-/underrepresentation metrics

## Usage:
```bash
# Generate historical demographic estimates from prompts
python generate_demographic_estimates.py \
  --input_txt path/to/prompts.txt \
  --output_json llm_demographics.json

#  Evaluate demographic alignment
python evaluate_demographic_alignment.py \
  --model_outputs_csv fairface_outputs.csv \
  --llm_json llm_demographics.json \
  --output_csv demographic_metrics.csv



