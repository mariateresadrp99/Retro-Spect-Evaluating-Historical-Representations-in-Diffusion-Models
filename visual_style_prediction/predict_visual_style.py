"""
Predict stylistic categories of TTI-generated images using a fine-tuned CNN classifier on WikiArt, available on Hugging Face.
If the style is 'photography', compute a colorfulness score to distinguish between monochrome and color photography.
Uses the HistVis dataset from Hugging Face which contains images generated by various TTI models.
"""
import os
import argparse
import pandas as pd
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from huggingface_hub import hf_hub_download
from datasets import load_dataset
from utils import predict_colorfulness, CLASS_NAMES

def preprocess_image(img_path):
    """
    Preprocess a single image before feeding it to the CNN model:
    - Resize to 224x224 (VGG16 default)
    - Normalize pixel values to [0, 1]
    - Expand dimensions to simulate batch size of 1
    """
    img = load_img(img_path, target_size=(224, 224))
    x = img_to_array(img) / 255.0
    return np.expand_dims(x, axis=0)

def predict_style(model, img_path):
    """
    Predict the stylistic category for a single image.
    Args:
        model: The loaded CNN model.
        img_path: Path to the image file.
    Returns:
        Predicted style label (str).
    """
    x = preprocess_image(img_path)
    preds = model.predict(x, verbose=0)
    return CLASS_NAMES[np.argmax(preds)]

def analyze_style_distribution(results_df):
    """
    Analyze and print style distribution statistics from predictions.
    
    Args:
        results_df: DataFrame containing style predictions
    """
    print("\nStyle Distribution Analysis:")
    
    # Overall style distribution
    style_counts = results_df['detailed_style'].value_counts()
    total = len(results_df)
    
    print("\nOverall Style Distribution:")
    for style, count in style_counts.items():
        percentage = (count / total) * 100
        print(f"  {style}: {count} images ({percentage:.1f}%)")
    
    # Style distribution by historical period
    if 'historical_period' in results_df.columns:
        print("\nStyle Distribution by Historical Period:")
        periods = results_df['historical_period'].unique()
        
        for period in sorted(periods):
            period_df = results_df[results_df['historical_period'] == period]
            period_counts = period_df['detailed_style'].value_counts()
            period_total = len(period_df)
            
            print(f"\n  {period} ({period_total} images):")
            for style, count in period_counts.items():
                percentage = (count / period_total) * 100
                print(f"    {style}: {count} images ({percentage:.1f}%)")
    
    # Style distribution by model
    if 'model' in results_df.columns:
        print("\nStyle Distribution by Model:")
        models = results_df['model'].unique()
        
        for model in sorted(models):
            model_df = results_df[results_df['model'] == model]
            model_counts = model_df['detailed_style'].value_counts()
            model_total = len(model_df)
            
            print(f"\n  {model} ({model_total} images):")
            for style, count in model_counts.items():
                percentage = (count / model_total) * 100
                print(f"    {style}: {count} images ({percentage:.1f}%)")

def main(args):
    """
    Main function to load the HistVis dataset, predict styles for images, and save results.
    """
    # Load the pretrained model from Hugging Face
    if args.use_hf_model:
        model_path = hf_hub_download(
            repo_id="mariateresadrp/visual_style_predictor",
            filename="best_vgg16_only_last.keras"
        )
        model = load_model(model_path)
        print(f"Loaded model from Hugging Face: mariateresadrp/visual_style_predictor")
    else:
        model = load_model(args.model_path)
        print(f"Loaded model from: {args.model_path}")
    
    # Load the HistVis dataset from Hugging Face
    if args.use_hf_dataset:
        print("Loading HistVis dataset from Hugging Face...")
        dataset = load_dataset('csv', data_files='https://huggingface.co/datasets/latentcanon/HistVis/resolve/main/dataset.csv')
        df = pd.DataFrame(dataset['train'])
        print(f"Dataset contains {len(df)} entries")
    else:
        # Load from local CSV file
        df = pd.read_csv(args.dataset_csv)
        print(f"Loaded {len(df)} entries from {args.dataset_csv}")
    
    # Create results list
    results = []
    
    # Process each image in the dataset
    for idx, row in df.iterrows():
        img_path = row['image_path']
        
        # Skip if image doesn't exist
        if not os.path.exists(img_path):
            print(f"‚ö†Image not found: {img_path}")
            continue
            
        try:
            style = predict_style(model, img_path)
            
            # Only compute colorfulness if the style is photography
            if style == "photography":
                colorfulness = predict_colorfulness(img_path)
                # Further classify as B&W or color photography based on threshold
                detailed_style = get_photography_type(colorfulness, args.colorfulness_threshold)
            else:
                colorfulness = None
                detailed_style = style
                
            # Create result entry, including original metadata
            result = {
                "image_path": img_path,
                "model": row.get('model', None),
                "historical_period": row.get('historical_period', None),
                "universal_human_activity": row.get('universal_human_activity', None),
                "category": row.get('category', None),
                "style_prediction": style,
                "detailed_style": detailed_style,
                "colorfulness_score": colorfulness
            }
            
            results.append(result)
            
            if (idx + 1) % 100 == 0:
                print(f"üîç Processed {idx + 1}/{len(df)} images...")
                
        except Exception as e:
            print(f"‚ö†Error processing {img_path}: {e}")
    
    # Save results to CSV
    results_df = pd.DataFrame(results)
    results_df.to_csv(args.output_file, index=False)
    print(f"\nDone! Saved predictions for {len(results_df)} images to: {args.output_file}")
    
    # Analyze style distribution if requested
    if args.analyze:
        analyze_style_distribution(results_df)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Predict stylistic categories for TTI-generated images from HistVis dataset")
    
    # Dataset options
    parser.add_argument("--use_hf_dataset", action="store_true", help="Use HistVis dataset directly from Hugging Face")
    parser.add_argument("--dataset_csv", default="dataset.csv", help="Path to the local dataset CSV file (if not using HistVis)")
    
    # Model options
    parser.add_argument("--use_hf_model", action="store_true", help="Use visual style predictor model from Hugging Face")
    parser.add_argument("--model_path", default="style_classifier/best_vgg16_only_last.keras", help="Path to local CNN model file (if not using our fine tuned one)")
    
    # Output options
    parser.add_argument("--output_file", default="style_predictions.csv", help="Output CSV file to store predictions")
    parser.add_argument("--colorfulness_threshold", type=float, default=10, help="Threshold for distinguishing B&W from color photography")
    parser.add_argument("--analyze", action="store_true", help="Analyze and print style distribution statistics")
    
    # Legacy options (for backward compatibility)
    parser.add_argument("--image_dir", help="[Legacy] Path to folder with images (use --dataset_csv instead)")
    
    args = parser.parse_args()
    main(args)
